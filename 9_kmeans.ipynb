{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- K-Nearest Neighbors (KNN) is a simple and effective supervised machine learning algorithm used for both classification and regression tasks. It classifies a data point based on how its neighbors are classified or predicts a value based on the values of its neighbors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "1. Initialization:\n",
    "   - Choose the number of neighbors (k).\n",
    "   - Select a distance metric (e.g., Euclidean, Manhattan, or Minkowski).\n",
    "2. For Classification:\n",
    "   - For a given data point:\n",
    "       - Calculate the distance between the point and all other points in the training dataset.\n",
    "       - Identify the k nearest neighbors.\n",
    "       - Assign the class label based on a majority vote of the neighbors.\n",
    "3. For Regression:\n",
    "   - Predict the output as the average of the values of the k nearest neighbors.\n",
    "   ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Euclidean Distance**\n",
    "\n",
    "Euclidean distance is a commonly used metric to measure the straight-line distance between two points in a Euclidean space. It is the most intuitive way of measuring the distance and is defined as the length of the shortest path between the two points.\n",
    "\n",
    "## **Definition**\n",
    "\n",
    "Given two points:\n",
    "\n",
    "- \\( P = (x_1, x_2, ..., x_n) \\)\n",
    "- \\( Q = (y_1, y_2, ...., y_n) \\)\n",
    "\n",
    "in an \\( n \\)-dimensional space, the Euclidean distance \\( d(P, Q) \\) is calculated as:\n",
    "\n",
    "$$\n",
    "d(P, Q) = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}\n",
    "$$\n",
    "\n",
    "### **Special Cases**\n",
    "1. **2D Space**:\n",
    "   For two points \\( P = (x_1, y_1) \\) and \\( Q = (x_2, y_2) \\), the Euclidean distance is:\n",
    "\n",
    "   $$\n",
    "   d(P, Q) = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}\n",
    "   $$\n",
    "\n",
    "2. **3D Space**:\n",
    "   For two points \\( P = (x_1, y_1, z_1) \\) and \\( Q = (x_2, y_2, z_2) \\), the Euclidean distance is:\n",
    "\n",
    "   $$\n",
    "   d(P, Q) = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2 + (z_2 - z_1)^2}\n",
    "   $$\n",
    "\n",
    "## **Key Points**\n",
    "- The Euclidean distance is sensitive to the scale of the features, so feature scaling (e.g., normalization) is often necessary when applying this metric.\n",
    "- It is commonly used in machine learning algorithms like **K-Nearest Neighbors (KNN)**, **K-Means Clustering**, and **Principal Component Analysis (PCA)**.\n",
    "- For higher-dimensional data, the interpretation of Euclidean distance can become less meaningful due to the **curse of dimensionality**.\n",
    "\n",
    "## **Applications**\n",
    "- **Clustering**: To measure the similarity between data points (e.g., in K-Means).\n",
    "- **Nearest Neighbors**: To identify the closest points (e.g., in KNN).\n",
    "- **Geometric Computations**: Calculating distances between points in space.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# **Manhattan Distance**\n",
    "\n",
    "Manhattan distance, also known as the **L1 norm** or **taxicab distance**, is a distance metric that measures the total absolute difference between the coordinates of two points. Unlike Euclidean distance, it calculates the distance by summing the absolute differences along each dimension.\n",
    "\n",
    "## **Definition**\n",
    "\n",
    "Given two points:\n",
    "\n",
    "- \\( P = (x_1, x_2, \\dots, x_n) \\)\n",
    "- \\( Q = (y_1, y_2, \\dots, y_n) \\)\n",
    "\n",
    "in an \\( n \\)-dimensional space, the Manhattan distance \\( d(P, Q) \\) is calculated as:\n",
    "\n",
    "$$\n",
    "d(P, Q) = \\sum_{i=1}^{n} |x_i - y_i|\n",
    "$$\n",
    "\n",
    "### **Special Cases**\n",
    "1. **2D Space**:\n",
    "   For two points \\( P = (x_1, y_1) \\) and \\( Q = (x_2, y_2) \\), the Manhattan distance is:\n",
    "\n",
    "   $$\n",
    "   d(P, Q) = |x_2 - x_1| + |y_2 - y_1|\n",
    "   $$\n",
    "\n",
    "2. **3D Space**:\n",
    "   For two points \\( P = (x_1, y_1, z_1) \\) and \\( Q = (x_2, y_2, z_2) \\), the Manhattan distance is:\n",
    "\n",
    "   $$\n",
    "   d(P, Q) = |x_2 - x_1| + |y_2 - y_1| + |z_2 - z_1|\n",
    "   $$\n",
    "\n",
    "## **Key Points**\n",
    "- The name \"Manhattan distance\" comes from the idea of navigating a grid-like street layout, such as in Manhattan, New York, where movement is restricted to vertical and horizontal paths.\n",
    "- It is less sensitive to outliers compared to Euclidean distance since it focuses on absolute differences.\n",
    "- Works well for high-dimensional data when features are uncorrelated and equally weighted.\n",
    "\n",
    "## **Applications**\n",
    "- **Clustering**: Used in algorithms like K-Medians or KNN when the data aligns better with grid-like or piecewise linear relationships.\n",
    "- **Pathfinding**: In grid-based games or maps where movement is constrained to vertical or horizontal paths.\n",
    "- **Feature Importance**: To measure distances in sparse or high-dimensional datasets where the L1 norm is more interpretable.\n",
    "\n",
    "## **Comparison with Euclidean Distance**\n",
    "- **Manhattan Distance**: Measures along the axes (grid-like paths).\n",
    "- **Euclidean Distance**: Measures the straight-line (shortest) distance.\n",
    "\n",
    "For example:\n",
    "- Points \\( P = (1, 2) \\) and \\( Q = (4, 6) \\):\n",
    "  - Manhattan Distance: \\( |4 - 1| + |6 - 2| = 3 + 4 = 7 \\)\n",
    "  - Euclidean Distance: \\( \\sqrt{(4 - 1)^2 + (6 - 2)^2} = \\sqrt{9 + 16} = 5 \\)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# **Minkowski Distance**\n",
    "\n",
    "Minkowski distance is a generalized distance metric that encompasses both **Euclidean** and **Manhattan** distances as special cases. It is a parameterized metric that measures the distance between two points in a normed vector space.\n",
    "\n",
    "## **Definition**\n",
    "\n",
    "Given two points:\n",
    "\n",
    "- \\( P = (x_1, x_2, \\dots, x_n) \\)\n",
    "- \\( Q = (y_1, y_2, \\dots, y_n) \\)\n",
    "\n",
    "in an \\( n \\)-dimensional space, the Minkowski distance \\( d(P, Q) \\) is calculated as:\n",
    "\n",
    "$$\n",
    "d(P, Q) = \\left( \\sum_{i=1}^{n} |x_i - y_i|^p \\right)^{\\frac{1}{p}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- \\( p \\) is the order of the Minkowski distance.\n",
    "- \\( n \\) is the number of dimensions.\n",
    "\n",
    "---\n",
    "\n",
    "## **Special Cases**\n",
    "1. **Manhattan Distance** (\\( p = 1 \\)):\n",
    "   For \\( p = 1 \\), Minkowski distance becomes Manhattan distance:\n",
    "\n",
    "   $$\n",
    "   d(P, Q) = \\sum_{i=1}^{n} |x_i - y_i|\n",
    "   $$\n",
    "\n",
    "2. **Euclidean Distance** (\\( p = 2 \\)):\n",
    "   For \\( p = 2 \\), Minkowski distance becomes Euclidean distance:\n",
    "\n",
    "   $$\n",
    "   d(P, Q) = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}\n",
    "   $$\n",
    "\n",
    "3. **Chebyshev Distance** (\\( p \\to \\infty \\)):\n",
    "   For \\( p \\to \\infty \\), Minkowski distance becomes Chebyshev distance, which is the maximum absolute difference between the coordinates of the points:\n",
    "\n",
    "   $$\n",
    "   d(P, Q) = \\max_{i=1}^{n} |x_i - y_i|\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Points**\n",
    "- The parameter \\( p \\) controls the behavior of the distance metric:\n",
    "  - \\( p = 1 \\): Focuses on axis-aligned differences (grid-based distance).\n",
    "  - \\( p = 2 \\): Captures the straight-line (shortest) distance.\n",
    "  - \\( p > 2 \\): Amplifies larger differences between coordinates.\n",
    "  - \\( p < 1 \\): Weighs smaller differences more heavily.\n",
    "\n",
    "- Minkowski distance is widely used in machine learning algorithms like K-Nearest Neighbors (KNN), where the choice of \\( p \\) depends on the nature of the data.\n",
    "\n",
    "---\n",
    "\n",
    "## **Applications**\n",
    "- **Generalized Distance Calculation**: Useful in datasets where the choice between Manhattan or Euclidean distance isn't obvious.\n",
    "- **Clustering and Classification**: As part of distance-based algorithms.\n",
    "- **Feature Importance**: Evaluates the contribution of different dimensions to the distance metric.\n",
    "\n",
    "---\n",
    "\n",
    "## **Example**\n",
    "- Points \\( P = (1, 2) \\) and \\( Q = (4, 6) \\):\n",
    "  - For \\( p = 1 \\) (Manhattan): \\( d(P, Q) = |4 - 1| + |6 - 2| = 3 + 4 = 7 \\)\n",
    "  - For \\( p = 2 \\) (Euclidean): \\( d(P, Q) = \\sqrt{(4 - 1)^2 + (6 - 2)^2} = \\sqrt{9 + 16} = 5 \\)\n",
    "  - For \\( p = 3 \\): \\( d(P, Q) = \\left( |4 - 1|^3 + |6 - 2|^3 \\right)^{\\frac{1}{3}} = \\left( 27 + 64 \\right)^{\\frac{1}{3}} = 4.6416 \\)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
