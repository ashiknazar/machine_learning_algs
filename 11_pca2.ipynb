{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13aea70f",
   "metadata": {},
   "source": [
    "# üìä Principal Component Analysis (PCA) - Step-by-Step Example\n",
    "\n",
    "We will explain PCA with 2 features and 5 samples. The goal is to reduce 2D data into 1D while retaining maximum variance.\n",
    "\n",
    "---\n",
    "\n",
    "## üî¢ Step 1: Input Data\n",
    "\n",
    "| Sample | $x_1$ | $x_2$ |\n",
    "|--------|------|------|\n",
    "| A      | 2    | 0    |\n",
    "| B      | 0    | 1    |\n",
    "| C      | 1    | 0    |\n",
    "| D      | 3    | 1    |\n",
    "| E      | 0    | 2    |\n",
    "\n",
    "$$\n",
    "X = \\begin{bmatrix}\n",
    "2 & 0 \\\\\n",
    "0 & 1 \\\\\n",
    "1 & 0 \\\\\n",
    "3 & 1 \\\\\n",
    "0 & 2 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## üßÆ Step 2: Mean Center the Data\n",
    "\n",
    "Compute the mean of each column:\n",
    "\n",
    "- $ \\bar{x}_1 = \\frac{2 + 0 + 1 + 3 + 0}{5} = \\frac{6}{5} = 1.2 $\n",
    "- $ \\bar{x}_2 = \\frac{0 + 1 + 0 + 1 + 2}{5} = \\frac{4}{5} = 0.8 $\n",
    "\n",
    "Subtract the mean from each value:\n",
    "\n",
    "$$\n",
    "X_{\\text{centered}} = X - \\bar{X} =\n",
    "\\begin{bmatrix}\n",
    "0.8 & -0.8 \\\\\n",
    "-1.2 & 0.2 \\\\\n",
    "-0.2 & -0.8 \\\\\n",
    "1.8 & 0.2 \\\\\n",
    "-1.2 & 1.2 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## üìè Step 3: Covariance Matrix\n",
    "\n",
    "Formula:\n",
    "\n",
    "$$\n",
    "\\text{Cov}(X) = \\frac{1}{n-1} X^T X\n",
    "$$\n",
    "\n",
    "Covariance matrix after calculation:\n",
    "\n",
    "$$\n",
    "\\text{Cov}(X) = \\frac{1}{4}\n",
    "\\begin{bmatrix}\n",
    "7.2 & -1.2 \\\\\n",
    "-1.2 & 1.7 \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "1.8 & -0.3 \\\\\n",
    "-0.3 & 0.425 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Step 4: Find Eigenvalues and Eigenvectors\n",
    "\n",
    "To find eigenvalues $ \\lambda $, solve:\n",
    "\n",
    "$$\n",
    "\\text{det}(C - \\lambda I) = 0\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$\n",
    "C = \n",
    "\\begin{bmatrix}\n",
    "1.8 & -0.3 \\\\\n",
    "-0.3 & 0.425 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Determinant equation:\n",
    "\n",
    "$$\n",
    "\\text{det}\n",
    "\\begin{bmatrix}\n",
    "1.8 - \\lambda & -0.3 \\\\\n",
    "-0.3 & 0.425 - \\lambda \\\\\n",
    "\\end{bmatrix}\n",
    "= (1.8 - \\lambda)(0.425 - \\lambda) - 0.09 = 0\n",
    "$$\n",
    "\n",
    "Expand:\n",
    "\n",
    "$$\n",
    "\\lambda^2 - 2.225\\lambda + 0.675 = 0\n",
    "$$\n",
    "\n",
    "Solve:\n",
    "\n",
    "$$\n",
    "\\lambda = \\frac{2.225 \\pm \\sqrt{(2.225)^2 - 4 \\cdot 0.675}}{2}\n",
    "= \\frac{2.225 \\pm \\sqrt{4.9506 - 2.7}}{2}\n",
    "= \\frac{2.225 \\pm \\sqrt{2.2506}}{2}\n",
    "$$\n",
    "\n",
    "So:\n",
    "\n",
    "- $ \\lambda_1 \\approx 1.84 $\n",
    "- $ \\lambda_2 \\approx 0.385 $\n",
    "\n",
    "Now find eigenvector for $ \\lambda_1 = 1.84 $:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1.8 - 1.84 & -0.3 \\\\\n",
    "-0.3 & 0.425 - 1.84 \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "-0.04 & -0.3 \\\\\n",
    "-0.3 & -1.415 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Solve:\n",
    "\n",
    "$$\n",
    "-0.04v_1 - 0.3v_2 = 0 \\Rightarrow v_1 = -\\frac{0.3}{0.04}v_2 = -7.5v_2\n",
    "$$\n",
    "\n",
    "So eigenvector is proportional to $ [1, -0.1333] $ (before normalization).\n",
    "\n",
    "---\n",
    "\n",
    "## üìâ Step 5: Project Data onto First Principal Component\n",
    "\n",
    "Let first eigenvector (unit vector) be:\n",
    "\n",
    "$$\n",
    "v_1 = \\begin{bmatrix} 0.99 \\\\ -0.13 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "X_{\\text{PCA}} = X_{\\text{centered}} \\cdot v_1 =\n",
    "\\begin{bmatrix}\n",
    "0.8 & -0.8 \\\\\n",
    "-1.2 & 0.2 \\\\\n",
    "-0.2 & -0.8 \\\\\n",
    "1.8 & 0.2 \\\\\n",
    "-1.2 & 1.2 \\\\\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix}\n",
    "0.99 \\\\\n",
    "-0.13 \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0.8(0.99) + (-0.8)(-0.13) = 0.896 \\\\\n",
    "-1.2(0.99) + 0.2(-0.13) = -1.214 \\\\\n",
    "-0.2(0.99) + (-0.8)(-0.13) = -0.094 \\\\\n",
    "1.8(0.99) + 0.2(-0.13) = 1.756 \\\\\n",
    "-1.2(0.99) + 1.2(-0.13) = -1.344 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Final Output: Reduced 1D Data\n",
    "\n",
    "$$\n",
    "\\text{PCA Output (1D)} =\n",
    "\\begin{bmatrix}\n",
    "0.896 \\\\\n",
    "-1.214 \\\\\n",
    "-0.094 \\\\\n",
    "1.756 \\\\\n",
    "-1.344 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This is the transformed data along the first principal component, effectively reducing 2D data into 1D.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14127b98",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7019cdff",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65151a2f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6f059a6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "209a9ce5",
   "metadata": {},
   "source": [
    "# üìä Principal Component Analysis (PCA) - Step-by-Step Example\n",
    "\n",
    "We will explain PCA with 2 features and 5 samples. The goal is to reduce 2D data into 1D while retaining maximum variance.\n",
    "\n",
    "---\n",
    "\n",
    "## üî¢ Step 1: Input Data\n",
    "\n",
    "| Sample | $x_1$ | $x_2$ |\n",
    "|--------|------|------|\n",
    "| A      | 2    | 0    |\n",
    "| B      | 0    | 1    |\n",
    "| C      | 1    | 0    |\n",
    "| D      | 3    | 1    |\n",
    "| E      | 0    | 2    |\n",
    "\n",
    "$$\n",
    "X = \\begin{bmatrix}\n",
    "2 & 0 \\\\\n",
    "0 & 1 \\\\\n",
    "1 & 0 \\\\\n",
    "3 & 1 \\\\\n",
    "0 & 2 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## üßÆ Step 2: Mean Center the Data\n",
    "\n",
    "Compute the mean of each column:\n",
    "\n",
    "- $ \\bar{x}_1 = \\frac{2 + 0 + 1 + 3 + 0}{5} = \\frac{6}{5} = 1.2 $\n",
    "- $ \\bar{x}_2 = \\frac{0 + 1 + 0 + 1 + 2}{5} = \\frac{4}{5} = 0.8 $\n",
    "\n",
    "Subtract the mean from each value:\n",
    "\n",
    "$$\n",
    "X_{\\text{centered}} = X - \\bar{X} =\n",
    "\\begin{bmatrix}\n",
    "0.8 & -0.8 \\\\\n",
    "-1.2 & 0.2 \\\\\n",
    "-0.2 & -0.8 \\\\\n",
    "1.8 & 0.2 \\\\\n",
    "-1.2 & 1.2 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## üìè Step 3: Covariance Matrix\n",
    "\n",
    "Formula:\n",
    "\n",
    "$$\n",
    "\\text{Cov}(X) = \\frac{1}{n-1} X^T X\n",
    "$$\n",
    "\n",
    "Covariance matrix after calculation:\n",
    "\n",
    "$$\n",
    "\\text{Cov}(X) = \\frac{1}{4}\n",
    "\\begin{bmatrix}\n",
    "7.2 & -1.2 \\\\\n",
    "-1.2 & 1.7 \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "1.8 & -0.3 \\\\\n",
    "-0.3 & 0.425 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Step 4: Find Eigenvalues and Eigenvectors\n",
    "\n",
    "To find eigenvalues $ \\lambda $, solve:\n",
    "\n",
    "$$\n",
    "\\text{det}(C - \\lambda I) = 0\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$\n",
    "C = \n",
    "\\begin{bmatrix}\n",
    "1.8 & -0.3 \\\\\n",
    "-0.3 & 0.425 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Determinant equation:\n",
    "\n",
    "$$\n",
    "\\text{det}\n",
    "\\begin{bmatrix}\n",
    "1.8 - \\lambda & -0.3 \\\\\n",
    "-0.3 & 0.425 - \\lambda \\\\\n",
    "\\end{bmatrix}\n",
    "= (1.8 - \\lambda)(0.425 - \\lambda) - 0.09 = 0\n",
    "$$\n",
    "\n",
    "Expand:\n",
    "\n",
    "$$\n",
    "\\lambda^2 - 2.225\\lambda + 0.675 = 0\n",
    "$$\n",
    "\n",
    "Solve:\n",
    "\n",
    "$$\n",
    "\\lambda = \\frac{2.225 \\pm \\sqrt{(2.225)^2 - 4 \\cdot 0.675}}{2}\n",
    "= \\frac{2.225 \\pm \\sqrt{4.9506 - 2.7}}{2}\n",
    "= \\frac{2.225 \\pm \\sqrt{2.2506}}{2}\n",
    "$$\n",
    "\n",
    "So:\n",
    "\n",
    "- $ \\lambda_1 \\approx 1.84 $\n",
    "- $ \\lambda_2 \\approx 0.385 $\n",
    "\n",
    "Now find eigenvector for $ \\lambda_1 = 1.84 $:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1.8 - 1.84 & -0.3 \\\\\n",
    "-0.3 & 0.425 - 1.84 \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "-0.04 & -0.3 \\\\\n",
    "-0.3 & -1.415 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Solve:\n",
    "\n",
    "$$\n",
    "-0.04v_1 - 0.3v_2 = 0 \\Rightarrow v_1 = -\\frac{0.3}{0.04}v_2 = -7.5v_2\n",
    "$$\n",
    "\n",
    "So eigenvector is proportional to $ [1, -0.1333] $ (before normalization).\n",
    "\n",
    "---\n",
    "\n",
    "To find the eigenvectors for a given eigenvalue $\\lambda$, we solve the equation:\n",
    "\n",
    "\n",
    "\n",
    "### üîπ Covariance Matrix (from earlier):\n",
    "\n",
    "$$\n",
    "C = \n",
    "\\begin{bmatrix}\n",
    "1.8 & -0.3 \\\\\n",
    "-0.3 & 0.425 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "We previously found one eigenvalue to be:\n",
    "\n",
    "$$\n",
    "\\lambda = 1.84\n",
    "$$\n",
    "\n",
    "Now subtract $\\lambda$ from the diagonal entries of $C$:\n",
    "\n",
    "$$\n",
    "C - \\lambda I = \n",
    "\\begin{bmatrix}\n",
    "1.8 - 1.84 & -0.3 \\\\\n",
    "-0.3 & 0.425 - 1.84 \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "-0.04 & -0.3 \\\\\n",
    "-0.3 & -1.415 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Set up the Equation:\n",
    "\n",
    "Now multiply the matrix with the unknown eigenvector $\\vec{v} = \\begin{bmatrix} v_1 \\\\ v_2 \\end{bmatrix}$:\n",
    "\n",
    "$$\n",
    "(C - \\lambda I)\\vec{v} =\n",
    "\\begin{bmatrix}\n",
    "-0.04v_1 - 0.3v_2 \\\\\n",
    "-0.3v_1 - 1.415v_2 \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This gives us a system of two linear equations:\n",
    "\n",
    "1. $-0.04v_1 - 0.3v_2 = 0$\n",
    "2. $-0.3v_1 - 1.415v_2 = 0$\n",
    "\n",
    "These two equations are linearly dependent (they give the same solution up to a scale), so we can use just the first:\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Solve for the Eigenvector Direction:\n",
    "\n",
    "From:\n",
    "\n",
    "$$\n",
    "-0.04v_1 - 0.3v_2 = 0\n",
    "$$\n",
    "\n",
    "We isolate $v_1$:\n",
    "\n",
    "$$\n",
    "v_1 = -\\frac{0.3}{0.04}v_2 = -7.5v_2\n",
    "$$\n",
    "\n",
    "So the eigenvector is proportional to:\n",
    "\n",
    "$$\n",
    "\\vec{v} =\n",
    "\\begin{bmatrix}\n",
    "-7.5 \\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "We can choose $v_2 = 1$ (any non-zero value works because eigenvectors are defined up to scale).\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Normalize the Eigenvector (Optional):\n",
    "\n",
    "To get a unit vector:\n",
    "\n",
    "$$\n",
    "\\|\\vec{v}\\| = \\sqrt{(-7.5)^2 + 1^2} = \\sqrt{56.25 + 1} = \\sqrt{57.25} \\approx 7.57\n",
    "$$\n",
    "\n",
    "So the normalized eigenvector is:\n",
    "\n",
    "$$\n",
    "\\vec{v}_{\\text{normalized}} = \\frac{1}{7.57}\n",
    "\\begin{bmatrix}\n",
    "-7.5 \\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "\\approx\n",
    "\\begin{bmatrix}\n",
    "-0.991 \\\\\n",
    "0.132 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "This eigenvector is now ready to be used to project the centered data onto the principal component!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad17083",
   "metadata": {},
   "source": [
    "## üß† Step-by-Step: Second Eigenvalue and Eigenvector\n",
    "\n",
    "We previously found the second eigenvalue to be:\n",
    "\n",
    "$$\n",
    "\\lambda_2 = 0.385\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Step 1: Build the Matrix $(C - \\lambda I)$\n",
    "\n",
    "We subtract $\\lambda$ from the diagonal elements of the covariance matrix:\n",
    "\n",
    "$$\n",
    "C - \\lambda_2 I =\n",
    "\\begin{bmatrix}\n",
    "1.8 - 0.385 & -0.3 \\\\\n",
    "-0.3 & 0.425 - 0.385 \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "1.415 & -0.3 \\\\\n",
    "-0.3 & 0.04 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Step 2: Multiply with the Eigenvector $\\vec{v}$\n",
    "\n",
    "Let:\n",
    "\n",
    "$$\n",
    "\\vec{v} =\n",
    "\\begin{bmatrix}\n",
    "v_1 \\\\\n",
    "v_2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1.415 & -0.3 \\\\\n",
    "-0.3 & 0.04 \\\\\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix}\n",
    "v_1 \\\\\n",
    "v_2\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "1.415v_1 - 0.3v_2 \\\\\n",
    "-0.3v_1 + 0.04v_2 \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Step 3: Solve the First Equation\n",
    "\n",
    "Take:\n",
    "\n",
    "$$\n",
    "1.415v_1 - 0.3v_2 = 0\n",
    "\\Rightarrow\n",
    "v_1 = \\frac{0.3}{1.415}v_2 \\approx 0.212v_2\n",
    "$$\n",
    "\n",
    "Let $v_2 = 1$:\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "v_1 = 0.212\n",
    "$$\n",
    "\n",
    "So the eigenvector is:\n",
    "\n",
    "$$\n",
    "\\vec{v} =\n",
    "\\begin{bmatrix}\n",
    "0.212 \\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Step 4: Normalize the Eigenvector\n",
    "\n",
    "Compute magnitude:\n",
    "\n",
    "$$\n",
    "\\|\\vec{v}\\| = \\sqrt{(0.212)^2 + 1^2} \\approx \\sqrt{0.0449 + 1} = \\sqrt{1.0449} \\approx 1.022\n",
    "$$\n",
    "\n",
    "Normalize:\n",
    "\n",
    "$$\n",
    "\\vec{v}_{\\text{normalized}} = \\frac{1}{1.022}\n",
    "\\begin{bmatrix}\n",
    "0.212 \\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "\\approx\n",
    "\\begin{bmatrix}\n",
    "0.207 \\\\\n",
    "0.979\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Final Second Eigenvector\n",
    "\n",
    "This is the **second principal component direction**, orthogonal to the first one:\n",
    "\n",
    "$$\n",
    "\\vec{v}_2 \\approx\n",
    "\\begin{bmatrix}\n",
    "0.207 \\\\\n",
    "0.979\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "You can now project the data onto this direction if you want a 2D representation with rotated axes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f097e59",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a639050f",
   "metadata": {},
   "source": [
    "## üìä Final Step: Project Data onto Both Principal Components\n",
    "\n",
    "We now project the centered data onto the two principal components (eigenvectors).\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Step 1: PCA Projection Formula\n",
    "\n",
    "If:\n",
    "- $X_{\\text{centered}}$ is the centered data matrix ($5 \\times 2$)\n",
    "- $V$ is the matrix of eigenvectors ($2 \\times 2$)\n",
    "\n",
    "Then the PCA-transformed data is:\n",
    "\n",
    "$$\n",
    "X_{\\text{PCA}} = X_{\\text{centered}} \\cdot V\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Step 2: Plug in the Values\n",
    "\n",
    "Let:\n",
    "\n",
    "$$\n",
    "X_{\\text{centered}} =\n",
    "\\begin{bmatrix}\n",
    "0.8 & -0.8 \\\\\n",
    "-1.2 & 0.2 \\\\\n",
    "-0.2 & -0.8 \\\\\n",
    "1.8 & 0.2 \\\\\n",
    "-1.2 & 1.2 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "V =\n",
    "\\begin{bmatrix}\n",
    "-0.991 & 0.207 \\\\\n",
    "0.132 & 0.979 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Now compute:\n",
    "\n",
    "$$\n",
    "X_{\\text{PCA}} = \n",
    "\\begin{bmatrix}\n",
    "0.8 & -0.8 \\\\\n",
    "-1.2 & 0.2 \\\\\n",
    "-0.2 & -0.8 \\\\\n",
    "1.8 & 0.2 \\\\\n",
    "-1.2 & 1.2 \\\\\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix}\n",
    "-0.991 & 0.207 \\\\\n",
    "0.132 & 0.979 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Step 3: Compute Each Row\n",
    "\n",
    "Let‚Äôs multiply row-by-row:\n",
    "\n",
    "- Row 1:  \n",
    "  $0.8(-0.991) + (-0.8)(0.132) = -0.793 - 0.106 = \\boxed{-0.899}$  \n",
    "  $0.8(0.207) + (-0.8)(0.979) = 0.166 - 0.783 = \\boxed{-0.617}$\n",
    "\n",
    "- Row 2:  \n",
    "  $-1.2(-0.991) + 0.2(0.132) = 1.189 + 0.026 = \\boxed{1.215}$  \n",
    "  $-1.2(0.207) + 0.2(0.979) = -0.248 + 0.196 = \\boxed{-0.052}$\n",
    "\n",
    "- Row 3:  \n",
    "  $-0.2(-0.991) + (-0.8)(0.132) = 0.198 - 0.106 = \\boxed{0.092}$  \n",
    "  $-0.2(0.207) + (-0.8)(0.979) = -0.041 - 0.783 = \\boxed{-0.824}$\n",
    "\n",
    "- Row 4:  \n",
    "  $1.8(-0.991) + 0.2(0.132) = -1.784 + 0.026 = \\boxed{-1.758}$  \n",
    "  $1.8(0.207) + 0.2(0.979) = 0.373 + 0.196 = \\boxed{0.569}$\n",
    "\n",
    "- Row 5:  \n",
    "  $-1.2(-0.991) + 1.2(0.132) = 1.189 + 0.158 = \\boxed{1.347}$  \n",
    "  $-1.2(0.207) + 1.2(0.979) = -0.248 + 1.175 = \\boxed{0.927}$\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Final PCA-Transformed Data (2D):\n",
    "\n",
    "$$\n",
    "X_{\\text{PCA}} =\n",
    "\\begin{bmatrix}\n",
    "-0.899 & -0.617 \\\\\n",
    "1.215 & -0.052 \\\\\n",
    "0.092 & -0.824 \\\\\n",
    "-1.758 & 0.569 \\\\\n",
    "1.347 & 0.927 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Each row is the new representation of the original sample in the **rotated PCA coordinate system**.\n",
    "\n",
    "- **First column** = coordinate along PC1\n",
    "- **Second column** = coordinate along PC2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab355831",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ca1e7b9",
   "metadata": {},
   "source": [
    "## üìâ Dimensionality Reduction (2D ‚Üí 1D)\n",
    "\n",
    "To reduce dimensionality from 2D to 1D, we only keep the **first principal component** (PC1), which captures the **most variance** in the data.\n",
    "\n",
    "From the 2D PCA result:\n",
    "\n",
    "$$\n",
    "X_{\\text{PCA}} =\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{-0.899} & -0.617 \\\\\n",
    "\\mathbf{1.215} & -0.052 \\\\\n",
    "\\mathbf{0.092} & -0.824 \\\\\n",
    "\\mathbf{-1.758} & 0.569 \\\\\n",
    "\\mathbf{1.347} & 0.927 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "We keep only the **first column** (PC1 projection):\n",
    "\n",
    "$$\n",
    "X_{\\text{reduced}} =\n",
    "\\begin{bmatrix}\n",
    "-0.899 \\\\\n",
    "1.215 \\\\\n",
    "0.092 \\\\\n",
    "-1.758 \\\\\n",
    "1.347 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This is your final **1D representation** of the original 2D data after PCA.\n",
    "\n",
    "- ‚úÖ Now it‚Äôs **compressed**\n",
    "- ‚úÖ Still captures the **maximum possible variance**\n",
    "- ‚úÖ Useful for **visualization**, **clustering**, or **speeding up ML models**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94123664",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e398649",
   "metadata": {},
   "source": [
    "## ‚úÖ Why We Chose PC1 for Dimensionality Reduction\n",
    "\n",
    "In PCA, each principal component (PC) has a corresponding **eigenvalue**, which tells us **how much variance** (i.e., information) that component captures from the original data.\n",
    "\n",
    "From our eigenvalue calculation:\n",
    "\n",
    "- $\\lambda_1 \\approx 1.84$ (for PC1)\n",
    "- $\\lambda_2 \\approx 0.385$ (for PC2)\n",
    "- Total variance = $1.84 + 0.385 = 2.225$\n",
    "\n",
    "We compute the **explained variance ratio**:\n",
    "\n",
    "- **PC1**: $\\frac{1.84}{2.225} \\approx 82.7\\%$\n",
    "- **PC2**: $\\frac{0.385}{2.225} \\approx 17.3\\%$\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Conclusion:\n",
    "\n",
    "Since **PC1 alone captures approximately 83% of the total variance**, it is the most informative direction.  \n",
    "That‚Äôs why we chose **PC1** as the single component for **dimensionality reduction (2D ‚Üí 1D)**.\n",
    "\n",
    "Keeping only PC1 allows us to reduce the number of features while preserving most of the meaningful structure in the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbee3a8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
