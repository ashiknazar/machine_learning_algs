{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Independent Component Analysis (ICA)**\n",
    "\n",
    "## **Overview**\n",
    "\n",
    "Independent Component Analysis (ICA) is a statistical method used to separate a multivariate signal into additive, independent components. It is primarily used in signal processing and data analysis, where the goal is to identify underlying sources from observed mixed signals. Unlike Principal Component Analysis (PCA), which looks for uncorrelated components, ICA focuses on **statistical independence** between the components.\n",
    "\n",
    "ICA is widely used in various fields, including:\n",
    "\n",
    "- **Blind source separation**: For example, separating mixed audio signals (e.g., cocktail party problem), where different sound sources (voices, music) are mixed together and recorded by microphones.\n",
    "- **Neuroscience**: For separating different brain activity patterns from EEG or fMRI data.\n",
    "- **Image processing**: For tasks like extracting independent features from images.\n",
    "\n",
    "---\n",
    "\n",
    "## **How ICA Works**\n",
    "\n",
    "ICA works by trying to find a transformation of the data such that the resulting components are **statistically independent**. Hereâ€™s a simplified overview of the steps involved:\n",
    "\n",
    "1. **Model the mixed signals**:\n",
    "   - Suppose you have observed data \\( X \\), which is a mixture of several independent sources \\( S \\). The observed data is represented as:\n",
    "     $$ X = A \\cdot S $$\n",
    "     Where:\n",
    "     - \\( X \\) is the matrix of observed signals (e.g., multiple sensors or channels).\n",
    "     - \\( A \\) is the mixing matrix that relates the sources to the observed signals.\n",
    "     - \\( S \\) is the matrix of independent source signals that we aim to recover.\n",
    "\n",
    "2. **Assume independence**:\n",
    "   - ICA assumes that the sources in \\( S \\) are statistically independent. Unlike PCA, which assumes uncorrelated components, ICA assumes that the source signals have non-Gaussian distributions and are mutually independent.\n",
    "\n",
    "3. **Estimate the unmixing matrix**:\n",
    "   - The goal of ICA is to find the **unmixing matrix** \\( W \\) that transforms the observed data \\( X \\) back into independent components:\n",
    "     $$ S = W \\cdot X $$\n",
    "\n",
    "4. **Maximize independence**:\n",
    "   - The unmixing matrix \\( W \\) is determined by maximizing the statistical independence of the components. This is often done using optimization techniques such as **minimizing mutual information** or **maximizing non-Gaussianity** of the components. \n",
    "\n",
    "---\n",
    "\n",
    "## **Mathematical Formulation**\n",
    "\n",
    "Given \\( X \\) as a matrix of observed signals and \\( S \\) as a matrix of independent sources, ICA attempts to find an unmixing matrix \\( W \\) such that:\n",
    "\n",
    "$$ S = W \\cdot X $$\n",
    "\n",
    "Where:\n",
    "- \\( X \\) is the observed data matrix (with \\( n \\) samples and \\( p \\) features).\n",
    "- \\( W \\) is the unmixing matrix (which is \\( p \\times p \\)).\n",
    "- \\( S \\) is the estimated independent sources.\n",
    "\n",
    "The key assumption in ICA is that the sources \\( S \\) are **independent** and that the observed signals \\( X \\) are linear mixtures of these sources.\n",
    "\n",
    "---\n",
    "\n",
    "## **Steps in ICA**\n",
    "\n",
    "1. **Center and whiten the data**:\n",
    "   - Center the data by subtracting the mean of each signal. Whitening is performed by transforming the data such that its covariance matrix is the identity matrix (i.e., making the components uncorrelated and with unit variance).\n",
    "   \n",
    "   $$ X_{\\text{whitened}} = E^{-1/2} \\cdot (X - \\mu) $$\n",
    "\n",
    "2. **Apply ICA algorithm**:\n",
    "   - ICA is typically performed using one of several algorithms, such as:\n",
    "     - **FastICA**: One of the most common and efficient algorithms for ICA.\n",
    "     - **InfoMax**: Uses mutual information maximization to identify independent components.\n",
    "     - **JADE (Joint Approximate Diagonalization of Eigenmatrices)**: Uses higher-order statistics to find independent components.\n",
    "\n",
    "3. **Extract independent components**:\n",
    "   - After applying the ICA algorithm, the output is a set of independent components \\( S \\) that ideally correspond to the original source signals.\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Differences Between ICA and PCA**\n",
    "\n",
    "| **Aspect**           | **PCA**                                  | **ICA**                                      |\n",
    "|----------------------|------------------------------------------|----------------------------------------------|\n",
    "| **Objective**         | Find uncorrelated components.            | Find statistically independent components.   |\n",
    "| **Assumptions**       | Assumes linearity and no correlation.    | Assumes linearity and statistical independence. |\n",
    "| **Output**            | Principal components (uncorrelated).     | Independent components (non-Gaussian).       |\n",
    "| **Use cases**         | Dimensionality reduction, visualization. | Blind source separation, signal processing.  |\n",
    "\n",
    "---\n",
    "\n",
    "## **Applications of ICA**\n",
    "\n",
    "ICA has a variety of real-world applications, including:\n",
    "\n",
    "1. **Blind Source Separation**: \n",
    "   - One of the classic problems in ICA is the **cocktail party problem**, where multiple sound sources (e.g., voices) are recorded by several microphones, and the goal is to separate the original sound sources.\n",
    "   \n",
    "2. **Neuroscience**: \n",
    "   - ICA is widely used to separate brain signals in EEG and fMRI data to study independent patterns of brain activity.\n",
    "   \n",
    "3. **Image Processing**: \n",
    "   - ICA can be used to extract independent features from images, such as separating facial features or objects from a set of mixed images.\n",
    "\n",
    "4. **Financial Market Analysis**:\n",
    "   - ICA is used to separate independent factors (e.g., market trends) from observed financial data.\n",
    "\n",
    "---\n",
    "\n",
    "## **Advantages of ICA**\n",
    "\n",
    "- **Separation of independent sources**: ICA can separate sources that are statistically independent, which is not possible with PCA, as PCA only finds uncorrelated components.\n",
    "- **Blind Source Separation**: ICA is especially useful in signal processing tasks, such as separating mixed signals from multiple sources without prior knowledge of the sources.\n",
    "\n",
    "---\n",
    "\n",
    "## **Disadvantages of ICA**\n",
    "\n",
    "- **Requires non-Gaussianity**: ICA assumes that the sources have non-Gaussian distributions. It may not work well if the sources are Gaussian or nearly Gaussian.\n",
    "- **Sensitive to preprocessing**: ICA performance is highly dependent on preprocessing steps like centering and whitening.\n",
    "- **Computationally expensive**: The optimization algorithms used in ICA, such as FastICA, can be computationally intensive, especially for high-dimensional datasets.\n",
    "\n",
    "---\n",
    "\n",
    "## **Example of ICA in Python**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# Generate sample data\n",
    "n_samples = 2000\n",
    "timepoints = np.linspace(0, 8, n_samples)\n",
    "s1 = np.sin(timepoints)  # Sine wave\n",
    "s2 = np.sign(np.sin(3 * timepoints))  # Square wave\n",
    "s3 = np.random.randn(n_samples)  # Gaussian noise\n",
    "\n",
    "# Stack the signals together to create independent sources\n",
    "S = np.c_[s1, s2, s3]\n",
    "S = S / S.std(axis=0)  # Standardize the sources\n",
    "\n",
    "# Mix the sources to create mixed signals\n",
    "A = np.array([[1, 2, 0.3], [0.5, 1, 1], [1, 1.5, 2]])  # Mixing matrix\n",
    "X = np.dot(S, A.T)  # Mixed signals\n",
    "\n",
    "# Apply ICA to recover independent components\n",
    "ica = FastICA(n_components=3)\n",
    "S_ = ica.fit_transform(X)  # Recovered signals\n",
    "A_ = ica.mixing_  # Estimated mixing matrix\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(7, 7))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title(\"Original Signals\")\n",
    "plt.plot(S)\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title(\"Mixed Signals\")\n",
    "plt.plot(X)\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title(\"Recovered Signals\")\n",
    "plt.plot(S_)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
