{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Metrics for Neural Networks\n",
    "\n",
    "Evaluating the performance of a neural network involves using various mathematical metrics, depending on the task (classification or regression). Below are some of the key performance metrics used in assessing neural network models.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Cross-Entropy Loss (for Classification)**\n",
    "\n",
    "Cross-entropy loss is used for classification tasks, measuring the difference between the true class labels and predicted probabilities.\n",
    "\n",
    "### Formula (Binary Classification):\n",
    "$$\n",
    "L_{\\text{binary}} = - \\left( y \\log(p) + (1 - y) \\log(1 - p) \\right)\n",
    "$$\n",
    "Where:\n",
    "- \\( y \\) = true class (0 or 1)\n",
    "- \\( p \\) = predicted probability for the positive class\n",
    "\n",
    "### Formula (Multi-Class Classification):\n",
    "$$\n",
    "L_{\\text{categorical}} = - \\sum_{i=1}^{C} y_i \\log(p_i)\n",
    "$$\n",
    "Where:\n",
    "- \\( y_i \\) = true label (1 for the correct class, 0 for others)\n",
    "- \\( p_i \\) = predicted probability for class \\( i \\)\n",
    "- \\( C \\) = number of classes\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Mean Squared Error (MSE) (for Regression)**\n",
    "\n",
    "MSE is a common loss function for regression tasks. It calculates the average squared difference between the true and predicted values.\n",
    "\n",
    "### Formula:\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "Where:\n",
    "- \\( y_i \\) = true value\n",
    "- \\( \\hat{y}_i \\) = predicted value\n",
    "- \\( N \\) = number of samples\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Accuracy (for Classification)**\n",
    "\n",
    "Accuracy is the ratio of correctly predicted instances to the total number of instances. It is most commonly used for classification tasks.\n",
    "\n",
    "### Formula:\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}} = \\frac{\\sum_{i=1}^{N} I(y_i = \\hat{y}_i)}{N}\n",
    "$$\n",
    "Where:\n",
    "- \\( y_i \\) = true class label\n",
    "- \\( \\hat{y}_i \\) = predicted class label\n",
    "- \\( I \\) = indicator function (1 if correct, 0 otherwise)\n",
    "- \\( N \\) = number of samples\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Precision, Recall, and F1-Score (for Classification)**\n",
    "\n",
    "These metrics are especially useful for imbalanced classes.\n",
    "\n",
    "### Precision:\n",
    "$$\n",
    "\\text{Precision} = \\frac{TP}{TP + FP}\n",
    "$$\n",
    "Where:\n",
    "- \\( TP \\) = True Positives\n",
    "- \\( FP \\) = False Positives\n",
    "\n",
    "### Recall:\n",
    "$$\n",
    "\\text{Recall} = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "Where:\n",
    "- \\( FN \\) = False Negatives\n",
    "\n",
    "### F1-Score:\n",
    "$$\n",
    "\\text{F1-Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## **5. ROC Curve and AUC (Area Under the Curve) (for Classification)**\n",
    "\n",
    "The **ROC curve** plots the **True Positive Rate (Recall)** vs **False Positive Rate**. The **AUC** quantifies the overall ability of the model to distinguish between classes.\n",
    "\n",
    "### True Positive Rate (TPR) and False Positive Rate (FPR):\n",
    "$$\n",
    "\\text{TPR} = \\frac{TP}{TP + FN}, \\quad \\text{FPR} = \\frac{FP}{FP + TN}\n",
    "$$\n",
    "Where:\n",
    "- \\( TN \\) = True Negatives\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Confusion Matrix (for Classification)**\n",
    "\n",
    "A confusion matrix helps assess the classification model's performance by comparing the predicted and actual values.\n",
    "\n",
    "|               | Predicted Positive (\\(\\hat{y}=1\\)) | Predicted Negative (\\(\\hat{y}=0\\)) |\n",
    "|---------------|-----------------------------------|-----------------------------------|\n",
    "| **Actual Positive (y=1)** | True Positive (TP) | False Negative (FN) |\n",
    "| **Actual Negative (y=0)** | False Positive (FP) | True Negative (TN) |\n",
    "\n",
    "- **Use**: The matrix helps calculate Precision, Recall, and other metrics.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Mean Absolute Error (MAE) (for Regression)**\n",
    "\n",
    "The Mean Absolute Error calculates the average absolute difference between the predicted and actual values.\n",
    "\n",
    "### Formula:\n",
    "$$\n",
    "\\text{MAE} = \\frac{1}{N} \\sum_{i=1}^{N} |y_i - \\hat{y}_i|\n",
    "$$\n",
    "Where:\n",
    "- \\( y_i \\) = true value\n",
    "- \\( \\hat{y}_i \\) = predicted value\n",
    "- \\( N \\) = number of samples\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Learning Curves (for Neural Networks)**\n",
    "\n",
    "Learning curves plot the model's performance (such as loss or accuracy) over time (or epochs). They help visualize model behavior and identify overfitting or underfitting.\n",
    "\n",
    "---\n",
    "\n",
    "## **9. RÂ² (Coefficient of Determination)**\n",
    "\n",
    "R-squared is a regression metric that indicates how well the independent variables explain the variance in the dependent variable.\n",
    "\n",
    "### Formula:\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{N} (y_i - \\bar{y})^2}\n",
    "$$\n",
    "Where:\n",
    "- \\( \\bar{y} \\) = mean of the actual values\n",
    "- \\( y_i \\) = true value\n",
    "- \\( \\hat{y}_i \\) = predicted value\n",
    "\n",
    "---\n",
    "\n",
    "## **10. Log-Loss (for Classification)**\n",
    "\n",
    "Log-Loss is another metric used for classification tasks where the output is a probability, similar to cross-entropy loss.\n",
    "\n",
    "### Formula:\n",
    "$$\n",
    "\\text{Log-Loss} = - \\frac{1}{N} \\sum_{i=1}^{N} \\left( y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \\right)\n",
    "$$\n",
    "Where:\n",
    "- \\( p_i \\) = predicted probability for class 1\n",
    "- \\( y_i \\) = true label (0 or 1)\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "These performance metrics provide different ways to assess the effectiveness of a neural network model. The choice of metric depends on the type of task (classification or regression) and the specific problem you are solving. Understanding these metrics is essential for evaluating model performance, detecting issues like overfitting, and making informed decisions on model optimization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
